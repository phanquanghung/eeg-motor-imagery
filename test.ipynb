{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ducanh/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu:  True\n"
     ]
    }
   ],
   "source": [
    "from braindecode.util import set_random_seeds, np_to_var, var_to_np\n",
    "import matplotlib.pyplot as plt\n",
    "from moabb.datasets import BNCI2014001, Cho2017, PhysionetMI\n",
    "from moabb.paradigms import MotorImagery\n",
    "import numpy as np\n",
    "from numpy.random import RandomState\n",
    "import pickle\n",
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import mne\n",
    "\n",
    "import start_kits.util.shallow_net\n",
    "from start_kits.util.utilfunc import get_balanced_batches\n",
    "from start_kits.util.preproc import plot_confusion_matrix\n",
    "\n",
    "from braindecode.models import ShallowFBCSPNet, EEGNetv1, EEGNetv4\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "print('gpu: ', cuda)\n",
    "device = 'cuda' if cuda else 'cpu'\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "rng = RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 32, 256)\n",
      "torch.Size([2, 32, 256, 1])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x_val = np.load('/home/ducanh/hain/hungp/NeurIPS_BEETL/numpy_data_binary/X_val.npy')\n",
    "\n",
    "# original shape: (num_trial, num_electrons, num_samples) with each trial is 1 label\n",
    "input = x_val[:2, :, :]\n",
    "input = input.astype('float32')\n",
    "print(input.shape)\n",
    "\n",
    "# add batch dims\n",
    "input = np.expand_dims(input, axis=0)\n",
    "\n",
    "# convert type to torch tensor\n",
    "input = torch.from_numpy(input)\n",
    "# reshape input size\n",
    "input = input.permute(1, 2, 3, 0)\n",
    "\n",
    "print(input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_chans = 32\n",
    "\n",
    "model = EEGNetv4(\n",
    "    in_chans = in_chans,\n",
    "    n_classes = 3,\n",
    "    input_window_samples=256,\n",
    ")\n",
    "\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "checkpoint = torch.load('cnn_model_mi.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "average_acc, average_loss = [], []\n",
    "setname = 'testset'\n",
    "dataset = test_set\n",
    "\n",
    "i_trials_in_batch = get_balanced_batches(len(dataset.X), rng, shuffle=False,\n",
    "                                         batch_size=batch_size)\n",
    "outputs=None\n",
    "for i_trials in i_trials_in_batch:\n",
    "    # Have to add empty fourth dimension to X\n",
    "    batch_X = dataset.X[i_trials][:, :, :, None]\n",
    "    batch_y = dataset.y[i_trials]\n",
    "    net_in = np_to_var(batch_X)\n",
    "    if cuda:\n",
    "        net_in = net_in.cuda()\n",
    "    toutputs = model(net_in)\n",
    "    if outputs is None:\n",
    "        temp = toutputs.cpu()\n",
    "        outputs = temp.detach().numpy()\n",
    "    else:\n",
    "        temp = toutputs.cpu()\n",
    "        outputs = np.concatenate((outputs,temp.detach().numpy()))\n",
    "\n",
    "net_target = np_to_var(dataset.y)\n",
    "loss = F.nll_loss(torch.from_numpy(outputs), net_target)\n",
    "print(\"{:6s} Loss: {:.5f}\".format(setname, float(var_to_np(loss))))\n",
    "predicted_labels = np.argmax((outputs), axis=1)\n",
    "accuracy = np.mean(dataset.y  == predicted_labels)\n",
    "\n",
    "print(\"{:6s} Accuracy: {:.1f}%\".format(setname, accuracy * 100))\n",
    "plot_confusion_matrix(dataset.y, predicted_labels, \n",
    "                      classes=['LH','Other'], normalize=True,\n",
    "                      title='Validation confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for EEGNetv4:\n\tsize mismatch for conv_spatial.weight: copying a param with shape torch.Size([16, 1, 22, 1]) from checkpoint, the shape in current model is torch.Size([16, 1, 32, 1]).\n\tsize mismatch for conv_classifier.weight: copying a param with shape torch.Size([3, 16, 1, 23]) from checkpoint, the shape in current model is torch.Size([3, 16, 1, 8]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/ducanh/hain/hungp/NeurIPS_BEETL/test.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsiliconcube.asuscomm.com/home/ducanh/hain/hungp/NeurIPS_BEETL/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsiliconcube.asuscomm.com/home/ducanh/hain/hungp/NeurIPS_BEETL/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mTODO: Load model pretrained here\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsiliconcube.asuscomm.com/home/ducanh/hain/hungp/NeurIPS_BEETL/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsiliconcube.asuscomm.com/home/ducanh/hain/hungp/NeurIPS_BEETL/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m checkpoint \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mcnn_model_mi.pth\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bsiliconcube.asuscomm.com/home/ducanh/hain/hungp/NeurIPS_BEETL/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m model\u001b[39m.\u001b[39;49mload_state_dict(checkpoint[\u001b[39m'\u001b[39;49m\u001b[39mmodel_state_dict\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsiliconcube.asuscomm.com/home/ducanh/hain/hungp/NeurIPS_BEETL/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mif\u001b[39;00m cuda:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsiliconcube.asuscomm.com/home/ducanh/hain/hungp/NeurIPS_BEETL/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mcuda()\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov4/lib/python3.8/site-packages/torch/nn/modules/module.py:1604\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1599\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   1600\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1601\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   1603\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 1604\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1605\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   1606\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for EEGNetv4:\n\tsize mismatch for conv_spatial.weight: copying a param with shape torch.Size([16, 1, 22, 1]) from checkpoint, the shape in current model is torch.Size([16, 1, 32, 1]).\n\tsize mismatch for conv_classifier.weight: copying a param with shape torch.Size([3, 16, 1, 23]) from checkpoint, the shape in current model is torch.Size([3, 16, 1, 8])."
     ]
    }
   ],
   "source": [
    "in_chans = 32\n",
    "\n",
    "model = EEGNetv4(\n",
    "    in_chans = in_chans,\n",
    "    n_classes = 3,\n",
    "    input_window_samples=256,\n",
    ")\n",
    "\n",
    "'''\n",
    "TODO: Load model pretrained here\n",
    "'''\n",
    "checkpoint = torch.load('cnn_model_mi.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "if cuda:\n",
    "    input = input.cuda()\n",
    "    model = model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/ducanh/hain/hungp/NeurIPS_BEETL/test.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bsiliconcube.asuscomm.com/home/ducanh/hain/hungp/NeurIPS_BEETL/test.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m out \u001b[39m=\u001b[39m model(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsiliconcube.asuscomm.com/home/ducanh/hain/hungp/NeurIPS_BEETL/test.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m out\u001b[39m.\u001b[39mshape\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov4/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov4/lib/python3.8/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov4/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov4/lib/python3.8/site-packages/torch/nn/modules/conv.py:457\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 457\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov4/lib/python3.8/site-packages/torch/nn/modules/conv.py:453\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    450\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    451\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    452\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 453\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    454\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "out = model(input)\n",
    "out.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('yolov4')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e122fa3ebfb795a2885f6aec974e3d1e6a66f6aebb6d7ae856fb30964b8ddec4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
